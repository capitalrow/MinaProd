/**
 * ðŸŽ¯ AUTOMATED QA PIPELINE
 * Comprehensive quality assessment with WER calculation and audio analysis
 */

class AutomatedQAPipeline {
    constructor() {
        this.qaSession = null;
        this.audioBuffer = [];
        this.transcriptBuffer = [];
        this.qualityMetrics = {
            wer: 0,
            accuracy: 0,
            latency: 0,
            completeness: 0,
            consistency: 0,
            drift: 0
        };
        
        this.thresholds = {
            wer_target: 10, // Target: â‰¤10% WER
            latency_target: 500, // Target: <500ms
            accuracy_target: 95, // Target: â‰¥95%
            completeness_target: 95 // Target: â‰¥95%
        };
        
        this.statistics = {
            totalSessions: 0,
            passedSessions: 0,
            failedSessions: 0,
            averageQuality: 0,
            issuesCounts: {
                highLatency: 0,
                lowAccuracy: 0,
                highWER: 0,
                incompleteness: 0
            }
        };
        
        console.log('ðŸŽ¯ Automated QA Pipeline initialized');
    }
    
    /**
     * Start a new QA session
     */
    startQASession(sessionId) {
        this.qaSession = {
            id: sessionId,
            startTime: Date.now(),
            audioChunks: [],
            transcriptSegments: [],
            expectedVsActual: [],
            qualityEvents: [],
            benchmarkResults: null
        };
        
        this.audioBuffer = [];
        this.transcriptBuffer = [];
        
        console.log(`ðŸŽ¯ QA session started: ${sessionId}`);
        return this.qaSession.id;
    }
    
    /**
     * Add audio chunk for analysis
     */
    addAudioChunk(audioData, timestamp, metadata = {}) {
        if (!this.qaSession) return;
        
        const chunk = {
            data: audioData,
            timestamp: timestamp,
            size: audioData.byteLength || audioData.length,
            metadata: metadata
        };
        
        this.qaSession.audioChunks.push(chunk);
        this.audioBuffer.push(chunk);
        
        // Analyze audio quality
        const audioQuality = this.analyzeAudioQuality(audioData);
        this.recordQualityEvent('audio_quality', audioQuality, timestamp);
    }
    
    /**
     * Add transcript segment for analysis
     */
    addTranscriptSegment(text, confidence, latency, isInterim = false, timestamp = Date.now()) {
        if (!this.qaSession) return;
        
        const segment = {
            text: text,
            confidence: confidence,
            latency: latency,
            isInterim: isInterim,
            timestamp: timestamp,
            wordCount: text.split(/\\s+/).length\n        };\n        \n        this.qaSession.transcriptSegments.push(segment);\n        if (!isInterim) {\n            this.transcriptBuffer.push(segment);\n        }\n        \n        // Analyze transcript quality\n        const transcriptQuality = this.analyzeTranscriptQuality(segment);\n        this.recordQualityEvent('transcript_quality', transcriptQuality, timestamp);\n        \n        // Update real-time metrics\n        this.updateRealTimeMetrics(segment);\n    }\n    \n    /**\n     * Analyze audio quality\n     */\n    analyzeAudioQuality(audioData) {\n        const rms = this.calculateRMS(audioData);\n        const snr = this.estimateSignalToNoiseRatio(audioData);\n        const dynamicRange = this.calculateDynamicRange(audioData);\n        \n        return {\n            rms: rms,\n            snr: snr,\n            dynamicRange: dynamicRange,\n            quality: this.calculateAudioQualityScore(rms, snr, dynamicRange)\n        };\n    }\n    \n    /**\n     * Calculate RMS (Root Mean Square) for audio data\n     */\n    calculateRMS(audioData) {\n        if (!audioData || audioData.length === 0) return 0;\n        \n        let sum = 0;\n        for (let i = 0; i < audioData.length; i++) {\n            const sample = audioData[i] || 0;\n            sum += sample * sample;\n        }\n        return Math.sqrt(sum / audioData.length);\n    }\n    \n    /**\n     * Estimate Signal-to-Noise Ratio\n     */\n    estimateSignalToNoiseRatio(audioData) {\n        if (!audioData || audioData.length === 0) return 0;\n        \n        // Simple SNR estimation based on signal variance\n        const rms = this.calculateRMS(audioData);\n        const mean = audioData.reduce((sum, val) => sum + (val || 0), 0) / audioData.length;\n        const variance = audioData.reduce((sum, val) => sum + Math.pow((val || 0) - mean, 2), 0) / audioData.length;\n        \n        const signalPower = rms * rms;\n        const noisePower = variance;\n        \n        return noisePower > 0 ? 10 * Math.log10(signalPower / noisePower) : 60; // Default to good SNR\n    }\n    \n    /**\n     * Calculate dynamic range\n     */\n    calculateDynamicRange(audioData) {\n        if (!audioData || audioData.length === 0) return 0;\n        \n        let min = audioData[0] || 0;\n        let max = audioData[0] || 0;\n        \n        for (let i = 1; i < audioData.length; i++) {\n            const sample = audioData[i] || 0;\n            if (sample < min) min = sample;\n            if (sample > max) max = sample;\n        }\n        \n        return max - min;\n    }\n    \n    /**\n     * Calculate audio quality score (0-100)\n     */\n    calculateAudioQualityScore(rms, snr, dynamicRange) {\n        // Normalize scores to 0-1\n        const rmsScore = Math.min(1, rms / 0.1); // Good RMS around 0.1\n        const snrScore = Math.min(1, Math.max(0, (snr - 10) / 40)); // 10-50 dB range\n        const dynamicScore = Math.min(1, dynamicRange / 1.0); // Good dynamic range\n        \n        // Weighted average\n        const score = (rmsScore * 0.4) + (snrScore * 0.4) + (dynamicScore * 0.2);\n        return Math.round(score * 100);\n    }\n    \n    /**\n     * Analyze transcript quality\n     */\n    analyzeTranscriptQuality(segment) {\n        const lengthScore = this.calculateLengthConsistency(segment.text);\n        const confidenceScore = segment.confidence;\n        const latencyScore = this.calculateLatencyScore(segment.latency);\n        const coherenceScore = this.calculateTextCoherence(segment.text);\n        \n        return {\n            lengthConsistency: lengthScore,\n            confidence: confidenceScore,\n            latency: latencyScore,\n            textCoherence: coherenceScore,\n            quality: this.calculateTranscriptQualityScore(lengthScore, confidenceScore, latencyScore, coherenceScore)\n        };\n    }\n    \n    /**\n     * Calculate length consistency score\n     */\n    calculateLengthConsistency(text) {\n        const wordCount = text.split(/\\s+/).length;\n        const charCount = text.length;\n        \n        // Good transcripts have reasonable word/char ratio\n        const ratio = wordCount > 0 ? charCount / wordCount : 0;\n        const expectedRatio = 5; // ~5 characters per word\n        \n        const consistency = 1 - Math.abs(ratio - expectedRatio) / expectedRatio;\n        return Math.max(0, Math.min(1, consistency));\n    }\n    \n    /**\n     * Calculate latency score (lower latency = higher score)\n     */\n    calculateLatencyScore(latency) {\n        const target = this.thresholds.latency_target;\n        if (latency <= target * 0.5) return 1.0;\n        if (latency <= target) return 0.8;\n        if (latency <= target * 1.5) return 0.6;\n        if (latency <= target * 2) return 0.4;\n        return 0.2;\n    }\n    \n    /**\n     * Calculate text coherence (basic linguistic analysis)\n     */\n    calculateTextCoherence(text) {\n        if (!text || text.length < 3) return 0;\n        \n        // Check for repeated words (indicates recognition errors)\n        const words = text.toLowerCase().split(/\\s+/);\n        const uniqueWords = new Set(words);\n        const repetitionRatio = uniqueWords.size / words.length;\n        \n        // Check for proper sentence structure\n        const sentences = text.split(/[.!?]/);\n        const avgSentenceLength = sentences.reduce((sum, s) => sum + s.trim().split(/\\s+/).length, 0) / sentences.length;\n        const sentenceScore = avgSentenceLength > 3 && avgSentenceLength < 25 ? 1 : 0.5;\n        \n        // Combined coherence score\n        return (repetitionRatio * 0.6) + (sentenceScore * 0.4);\n    }\n    \n    /**\n     * Calculate transcript quality score (0-100)\n     */\n    calculateTranscriptQualityScore(length, confidence, latency, coherence) {\n        const score = (length * 0.2) + (confidence * 0.4) + (latency * 0.2) + (coherence * 0.2);\n        return Math.round(score * 100);\n    }\n    \n    /**\n     * Update real-time metrics\n     */\n    updateRealTimeMetrics(segment) {\n        if (!this.transcriptBuffer.length) return;\n        \n        // Calculate average confidence\n        const avgConfidence = this.transcriptBuffer.reduce((sum, s) => sum + s.confidence, 0) / this.transcriptBuffer.length;\n        this.qualityMetrics.accuracy = avgConfidence * 100;\n        \n        // Calculate average latency\n        const avgLatency = this.transcriptBuffer.reduce((sum, s) => sum + s.latency, 0) / this.transcriptBuffer.length;\n        this.qualityMetrics.latency = avgLatency;\n        \n        // Calculate completeness (audio chunks vs transcript segments)\n        const audioChunks = this.qaSession.audioChunks.length;\n        const transcriptSegments = this.transcriptBuffer.length;\n        this.qualityMetrics.completeness = audioChunks > 0 ? (transcriptSegments / audioChunks) * 100 : 0;\n        \n        // Estimate WER (simplified)\n        this.qualityMetrics.wer = this.estimateWER();\n    }\n    \n    /**\n     * Estimate Word Error Rate based on confidence and consistency\n     */\n    estimateWER() {\n        if (this.transcriptBuffer.length < 2) return 0;\n        \n        let errorIndicators = 0;\n        let totalComparisons = 0;\n        \n        for (const segment of this.transcriptBuffer) {\n            // Low confidence indicates potential errors\n            if (segment.confidence < 0.7) errorIndicators++;\n            \n            // High latency indicates processing difficulty\n            if (segment.latency > this.thresholds.latency_target * 1.5) errorIndicators++;\n            \n            // Check for unusual word patterns\n            const coherence = this.calculateTextCoherence(segment.text);\n            if (coherence < 0.5) errorIndicators++;\n            \n            totalComparisons += 3;\n        }\n        \n        return totalComparisons > 0 ? (errorIndicators / totalComparisons) * 100 : 0;\n    }\n    \n    /**\n     * Calculate Word Error Rate with reference text\n     */\n    calculateWER(reference, hypothesis) {\n        if (!reference || !hypothesis) return 0;\n        \n        const refWords = this.normalizeText(reference).split(/\\s+/);\n        const hypWords = this.normalizeText(hypothesis).split(/\\s+/);\n        \n        const editDistance = this.calculateEditDistance(refWords, hypWords);\n        return refWords.length > 0 ? (editDistance / refWords.length) * 100 : 0;\n    }\n    \n    /**\n     * Normalize text for comparison\n     */\n    normalizeText(text) {\n        return text.toLowerCase()\n                  .replace(/[^a-z0-9\\s]/g, '') // Remove punctuation\n                  .replace(/\\s+/g, ' ')        // Normalize whitespace\n                  .trim();\n    }\n    \n    /**\n     * Calculate edit distance (Levenshtein distance) between word arrays\n     */\n    calculateEditDistance(arr1, arr2) {\n        const m = arr1.length;\n        const n = arr2.length;\n        const dp = Array(m + 1).fill().map(() => Array(n + 1).fill(0));\n        \n        // Initialize base cases\n        for (let i = 0; i <= m; i++) dp[i][0] = i;\n        for (let j = 0; j <= n; j++) dp[0][j] = j;\n        \n        // Fill the dp table\n        for (let i = 1; i <= m; i++) {\n            for (let j = 1; j <= n; j++) {\n                if (arr1[i - 1] === arr2[j - 1]) {\n                    dp[i][j] = dp[i - 1][j - 1];\n                } else {\n                    dp[i][j] = 1 + Math.min(\n                        dp[i - 1][j],     // deletion\n                        dp[i][j - 1],     // insertion\n                        dp[i - 1][j - 1]  // substitution\n                    );\n                }\n            }\n        }\n        \n        return dp[m][n];\n    }\n    \n    /**\n     * Record quality event\n     */\n    recordQualityEvent(type, data, timestamp) {\n        if (!this.qaSession) return;\n        \n        this.qaSession.qualityEvents.push({\n            type: type,\n            data: data,\n            timestamp: timestamp\n        });\n    }\n    \n    /**\n     * Run comprehensive quality assessment\n     */\n    runQualityAssessment() {\n        if (!this.qaSession) return null;\n        \n        const assessment = {\n            sessionId: this.qaSession.id,\n            duration: Date.now() - this.qaSession.startTime,\n            metrics: { ...this.qualityMetrics },\n            thresholds: { ...this.thresholds },\n            passed: this.checkQualityThresholds(),\n            issues: this.identifyQualityIssues(),\n            recommendations: this.generateRecommendations(),\n            timestamp: new Date().toISOString()\n        };\n        \n        this.qaSession.benchmarkResults = assessment;\n        this.updateStatistics(assessment);\n        \n        return assessment;\n    }\n    \n    /**\n     * Check if quality metrics meet thresholds\n     */\n    checkQualityThresholds() {\n        return {\n            wer: this.qualityMetrics.wer <= this.thresholds.wer_target,\n            latency: this.qualityMetrics.latency <= this.thresholds.latency_target,\n            accuracy: this.qualityMetrics.accuracy >= this.thresholds.accuracy_target,\n            completeness: this.qualityMetrics.completeness >= this.thresholds.completeness_target,\n            overall: (\n                this.qualityMetrics.wer <= this.thresholds.wer_target &&\n                this.qualityMetrics.latency <= this.thresholds.latency_target &&\n                this.qualityMetrics.accuracy >= this.thresholds.accuracy_target &&\n                this.qualityMetrics.completeness >= this.thresholds.completeness_target\n            )\n        };\n    }\n    \n    /**\n     * Identify quality issues\n     */\n    identifyQualityIssues() {\n        const issues = [];\n        \n        if (this.qualityMetrics.wer > this.thresholds.wer_target) {\n            issues.push({\n                type: 'high_wer',\n                severity: 'high',\n                message: `Word Error Rate (${this.qualityMetrics.wer.toFixed(1)}%) exceeds target (${this.thresholds.wer_target}%)`,\n                value: this.qualityMetrics.wer\n            });\n        }\n        \n        if (this.qualityMetrics.latency > this.thresholds.latency_target) {\n            issues.push({\n                type: 'high_latency',\n                severity: 'medium',\n                message: `Average latency (${this.qualityMetrics.latency.toFixed(0)}ms) exceeds target (${this.thresholds.latency_target}ms)`,\n                value: this.qualityMetrics.latency\n            });\n        }\n        \n        if (this.qualityMetrics.accuracy < this.thresholds.accuracy_target) {\n            issues.push({\n                type: 'low_accuracy',\n                severity: 'high',\n                message: `Accuracy (${this.qualityMetrics.accuracy.toFixed(1)}%) below target (${this.thresholds.accuracy_target}%)`,\n                value: this.qualityMetrics.accuracy\n            });\n        }\n        \n        if (this.qualityMetrics.completeness < this.thresholds.completeness_target) {\n            issues.push({\n                type: 'incomplete_processing',\n                severity: 'medium',\n                message: `Completeness (${this.qualityMetrics.completeness.toFixed(1)}%) below target (${this.thresholds.completeness_target}%)`,\n                value: this.qualityMetrics.completeness\n            });\n        }\n        \n        return issues;\n    }\n    \n    /**\n     * Generate recommendations for improvement\n     */\n    generateRecommendations() {\n        const recommendations = [];\n        const issues = this.identifyQualityIssues();\n        \n        for (const issue of issues) {\n            switch (issue.type) {\n                case 'high_wer':\n                    recommendations.push('Improve audio quality, check microphone positioning, reduce background noise');\n                    break;\n                case 'high_latency':\n                    recommendations.push('Optimize chunk size, check network connectivity, consider edge processing');\n                    break;\n                case 'low_accuracy':\n                    recommendations.push('Verify audio input quality, check for proper VAD settings, review language model');\n                    break;\n                case 'incomplete_processing':\n                    recommendations.push('Check for dropped chunks, verify error handling, review session management');\n                    break;\n            }\n        }\n        \n        if (recommendations.length === 0) {\n            recommendations.push('Quality metrics are within acceptable ranges. Continue current configuration.');\n        }\n        \n        return recommendations;\n    }\n    \n    /**\n     * Update overall statistics\n     */\n    updateStatistics(assessment) {\n        this.statistics.totalSessions++;\n        \n        if (assessment.passed.overall) {\n            this.statistics.passedSessions++;\n        } else {\n            this.statistics.failedSessions++;\n            \n            // Count specific issue types\n            for (const issue of assessment.issues) {\n                switch (issue.type) {\n                    case 'high_latency':\n                        this.statistics.issuesCounts.highLatency++;\n                        break;\n                    case 'low_accuracy':\n                        this.statistics.issuesCounts.lowAccuracy++;\n                        break;\n                    case 'high_wer':\n                        this.statistics.issuesCounts.highWER++;\n                        break;\n                    case 'incomplete_processing':\n                        this.statistics.issuesCounts.incompleteness++;\n                        break;\n                }\n            }\n        }\n        \n        // Update average quality\n        const overallQuality = this.calculateOverallQuality(assessment.metrics);\n        this.statistics.averageQuality = (\n            (this.statistics.averageQuality * (this.statistics.totalSessions - 1)) + overallQuality\n        ) / this.statistics.totalSessions;\n    }\n    \n    /**\n     * Calculate overall quality score\n     */\n    calculateOverallQuality(metrics) {\n        const latencyScore = Math.max(0, 100 - (metrics.latency / this.thresholds.latency_target) * 100);\n        const werScore = Math.max(0, 100 - (metrics.wer / this.thresholds.wer_target) * 100);\n        \n        return (metrics.accuracy * 0.3) + (latencyScore * 0.3) + (werScore * 0.2) + (metrics.completeness * 0.2);\n    }\n    \n    /**\n     * End QA session and generate final report\n     */\n    endQASession() {\n        if (!this.qaSession) return null;\n        \n        const finalAssessment = this.runQualityAssessment();\n        const sessionSummary = {\n            ...finalAssessment,\n            sessionSummary: {\n                audioChunks: this.qaSession.audioChunks.length,\n                transcriptSegments: this.qaSession.transcriptSegments.length,\n                qualityEvents: this.qaSession.qualityEvents.length,\n                totalWords: this.transcriptBuffer.reduce((sum, s) => sum + s.wordCount, 0)\n            }\n        };\n        \n        console.log('ðŸŽ¯ QA session completed:', sessionSummary.sessionId);\n        console.log('ðŸ“Š Quality Assessment:', finalAssessment);\n        \n        this.qaSession = null;\n        return sessionSummary;\n    }\n    \n    /**\n     * Get current QA statistics\n     */\n    getStatistics() {\n        const passRate = this.statistics.totalSessions > 0 \n            ? (this.statistics.passedSessions / this.statistics.totalSessions) * 100 \n            : 0;\n            \n        return {\n            ...this.statistics,\n            passRate: Math.round(passRate * 10) / 10,\n            currentMetrics: { ...this.qualityMetrics }\n        };\n    }\n    \n    /**\n     * Export QA data for analysis\n     */\n    exportQAData() {\n        const exportData = {\n            statistics: this.getStatistics(),\n            currentSession: this.qaSession,\n            thresholds: this.thresholds,\n            exportTimestamp: new Date().toISOString()\n        };\n        \n        const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json' });\n        const url = URL.createObjectURL(blob);\n        \n        const a = document.createElement('a');\n        a.href = url;\n        a.download = `mina-qa-data-${Date.now()}.json`;\n        document.body.appendChild(a);\n        a.click();\n        document.body.removeChild(a);\n        URL.revokeObjectURL(url);\n        \n        return exportData;\n    }\n}\n\n// Initialize global QA pipeline\nwindow.automatedQA = new AutomatedQAPipeline();\n\nconsole.log('âœ… Automated QA Pipeline loaded');"

// [CTO] Defaults to ensure live interim is visible & frequent
window.MINA_FEATURES = Object.assign({
  ENABLE_INTERIM: true,
  SHOW_INTERIM: true,
  REPLACE_INTERIM_ON_FINAL: true,
  INTERIM_THROTTLE_MS: 250,
  RECORDER_TIMESLICE_MS: 250,
}, window.MINA_FEATURES || {});
