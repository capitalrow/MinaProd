/**
 * ðŸ”¬ COMPREHENSIVE QA PIPELINE
 * Enhanced audio vs transcript quality analysis with WER calculation
 */

class ComprehensiveQAPipeline {
    constructor() {
        this.audioBuffer = [];
        this.transcriptBuffer = [];
        this.currentSession = null;
        this.qaMetrics = {
            wer: 0,
            accuracy: 0,
            latency: 0,
            completeness: 0,
            drift: 0,
            duplicates: 0,
            hallucinations: 0
        };
        
        this.referenceAudio = null;
        this.processingStartTime = null;
        
        console.log('ðŸ”¬ Comprehensive QA Pipeline initialized');
    }
    
    /**
     * Start QA session with audio recording
     */
    startQASession(sessionId) {
        this.currentSession = {
            id: sessionId,
            startTime: Date.now(),
            audioChunks: [],
            transcriptSegments: [],
            metrics: {
                totalAudioDuration: 0,
                totalWords: 0,
                avgConfidence: 0,
                latencies: [],
                errors: []
            }
        };
        
        this.startAudioRecording();
        console.log(`ðŸ”¬ QA Session started: ${sessionId}`);
    }
    
    /**
     * Start recording audio for comparison
     */\n    startAudioRecording() {\n        if (typeof MediaRecorder === 'undefined') {\n            console.warn('\u26a0\ufe0f MediaRecorder not available - QA will use transcript-only analysis');\n            return;\n        }\n        \n        // Request microphone access\n        navigator.mediaDevices.getUserMedia({ audio: true })\n            .then(stream => {\n                this.mediaRecorder = new MediaRecorder(stream, {\n                    mimeType: 'audio/webm;codecs=opus'\n                });\n                \n                this.mediaRecorder.ondataavailable = (event) => {\n                    if (event.data.size > 0) {\n                        this.currentSession.audioChunks.push({\n                            blob: event.data,\n                            timestamp: Date.now(),\n                            size: event.data.size\n                        });\n                    }\n                };\n                \n                this.mediaRecorder.start(1000); // 1 second chunks\n                console.log('\u2705 QA audio recording started');\n            })\n            .catch(error => {\n                console.warn('\u26a0\ufe0f QA audio recording failed:', error.message);\n                // Continue with transcript-only analysis\n            });\n    }\n    \n    /**\n     * Add transcript segment for analysis\n     */\n    addTranscriptSegment(text, confidence, latency, isInterim = false, timestamp = Date.now()) {\n        if (!this.currentSession) {\n            console.warn('\u26a0\ufe0f No active QA session');\n            return;\n        }\n        \n        const segment = {\n            text: text.trim(),\n            confidence: confidence || 0,\n            latency: latency || 0,\n            isInterim: isInterim,\n            timestamp: timestamp,\n            wordCount: text.trim().split(/\\s+/).length\n        };\n        \n        this.currentSession.transcriptSegments.push(segment);\n        \n        // Update real-time metrics\n        this.updateRealTimeMetrics(segment);\n        \n        // Calculate WER if we have enough data\n        if (this.currentSession.transcriptSegments.length >= 3) {\n            this.calculateWER();\n        }\n        \n        console.log(`\ud83d\udcdd Transcript segment added: \"${text.substring(0, 30)}...\" (confidence: ${(confidence * 100).toFixed(1)}%)`);\n    }\n    \n    /**\n     * Update real-time QA metrics\n     */\n    updateRealTimeMetrics(segment) {\n        const session = this.currentSession;\n        \n        // Update aggregated metrics\n        session.metrics.totalWords += segment.wordCount;\n        session.metrics.latencies.push(segment.latency);\n        \n        // Calculate running average confidence\n        const confidences = session.transcriptSegments.map(s => s.confidence);\n        session.metrics.avgConfidence = confidences.reduce((a, b) => a + b, 0) / confidences.length;\n        \n        // Detect potential issues\n        this.detectQualityIssues(segment);\n    }\n    \n    /**\n     * Calculate Word Error Rate using advanced heuristics\n     */\n    calculateWER() {\n        const segments = this.currentSession.transcriptSegments;\n        if (segments.length < 2) return 0;\n        \n        // Use the advanced real-time WER calculator if available\n        if (window.realTimeWERCalculator) {\n            const latestSegment = segments[segments.length - 1];\n            this.qaMetrics.wer = window.realTimeWERCalculator.calculateWEREstimate(\n                latestSegment.text, \n                latestSegment.confidence\n            );\n        } else {\n            // Fallback WER estimation\n            this.qaMetrics.wer = this.estimateWERFromTranscripts(segments);\n        }\n        \n        return this.qaMetrics.wer;\n    }\n    \n    /**\n     * Estimate WER from transcript characteristics\n     */\n    estimateWERFromTranscripts(segments) {\n        let errorIndicators = 0;\n        let totalComparisons = 0;\n        \n        // Analyze recent segments\n        const recentSegments = segments.slice(-5);\n        \n        for (const segment of recentSegments) {\n            // Low confidence indicates potential errors\n            if (segment.confidence < 0.7) errorIndicators++;\n            \n            // High latency indicates processing difficulty\n            if (segment.latency > 2000) errorIndicators++;\n            \n            // Very short segments often indicate errors\n            if (segment.text.length < 3) errorIndicators++;\n            \n            // Check for repetitive patterns\n            if (this.detectRepetitiveContent(segment.text, recentSegments)) {\n                errorIndicators++;\n            }\n            \n            // Check for unusual word patterns\n            if (this.detectUnusualPatterns(segment.text)) {\n                errorIndicators++;\n            }\n            \n            totalComparisons += 5;\n        }\n        \n        return totalComparisons > 0 ? (errorIndicators / totalComparisons) * 100 : 0;\n    }\n    \n    /**\n     * Detect repetitive content\n     */\n    detectRepetitiveContent(text, segments) {\n        const recentTexts = segments.slice(-3).map(s => s.text.toLowerCase());\n        const currentText = text.toLowerCase();\n        \n        // Check for exact duplicates\n        return recentTexts.filter(t => t === currentText).length > 1;\n    }\n    \n    /**\n     * Detect unusual word patterns\n     */\n    detectUnusualPatterns(text) {\n        const words = text.toLowerCase().split(/\\s+/);\n        \n        // Check for:\n        // 1. Too many single-letter words\n        const singleLetterWords = words.filter(w => w.length === 1).length;\n        if (singleLetterWords > words.length * 0.3) return true;\n        \n        // 2. Repeated words\n        const wordCounts = {};\n        words.forEach(word => {\n            wordCounts[word] = (wordCounts[word] || 0) + 1;\n        });\n        const maxRepeats = Math.max(...Object.values(wordCounts));\n        if (maxRepeats > 3 && words.length < 10) return true;\n        \n        // 3. Non-words (sequences without vowels)\n        const nonWords = words.filter(w => \n            w.length > 2 && !/[aeiou]/.test(w)\n        ).length;\n        if (nonWords > words.length * 0.4) return true;\n        \n        return false;\n    }\n    \n    /**\n     * Detect quality issues in real-time\n     */\n    detectQualityIssues(segment) {\n        const issues = [];\n        \n        // High latency warning\n        if (segment.latency > 3000) {\n            issues.push(`High latency: ${segment.latency}ms`);\n        }\n        \n        // Low confidence warning\n        if (segment.confidence < 0.6) {\n            issues.push(`Low confidence: ${(segment.confidence * 100).toFixed(1)}%`);\n        }\n        \n        // Empty or very short transcripts\n        if (segment.text.length < 2) {\n            issues.push('Very short transcript');\n        }\n        \n        // Potential duplicates\n        const recentSegments = this.currentSession.transcriptSegments.slice(-3);\n        if (this.detectRepetitiveContent(segment.text, recentSegments)) {\n            issues.push('Potential duplicate content');\n            this.qaMetrics.duplicates++;\n        }\n        \n        // Log issues\n        if (issues.length > 0) {\n            console.warn(`\u26a0\ufe0f QA Issues detected:`, issues);\n            this.currentSession.metrics.errors.push({\n                timestamp: segment.timestamp,\n                issues: issues,\n                text: segment.text\n            });\n        }\n    }\n    \n    /**\n     * Calculate comprehensive accuracy metrics\n     */\n    calculateAccuracy() {\n        if (!this.currentSession || this.currentSession.transcriptSegments.length === 0) {\n            return 0;\n        }\n        \n        const segments = this.currentSession.transcriptSegments;\n        const avgConfidence = this.currentSession.metrics.avgConfidence;\n        \n        // Base accuracy on confidence and quality indicators\n        let accuracy = avgConfidence * 100;\n        \n        // Adjust for quality issues\n        const errorRate = this.currentSession.metrics.errors.length / segments.length;\n        accuracy -= (errorRate * 20); // Reduce accuracy for errors\n        \n        // Adjust for latency (slower processing often means lower accuracy)\n        const avgLatency = this.currentSession.metrics.latencies.reduce((a, b) => a + b, 0) / this.currentSession.metrics.latencies.length;\n        if (avgLatency > 2000) {\n            accuracy -= 5; // Reduce accuracy for high latency\n        }\n        \n        this.qaMetrics.accuracy = Math.max(0, Math.min(100, accuracy));\n        return this.qaMetrics.accuracy;\n    }\n    \n    /**\n     * Calculate latency metrics\n     */\n    calculateLatency() {\n        if (!this.currentSession || this.currentSession.metrics.latencies.length === 0) {\n            return 0;\n        }\n        \n        const latencies = this.currentSession.metrics.latencies;\n        this.qaMetrics.latency = latencies.reduce((a, b) => a + b, 0) / latencies.length;\n        return this.qaMetrics.latency;\n    }\n    \n    /**\n     * Calculate completeness (coverage of audio)\n     */\n    calculateCompleteness() {\n        if (!this.currentSession) return 0;\n        \n        const sessionDuration = Date.now() - this.currentSession.startTime;\n        const transcriptSegments = this.currentSession.transcriptSegments.length;\n        \n        // Estimate expected segments based on session duration\n        const expectedSegments = Math.floor(sessionDuration / 2000); // Expect segment every 2 seconds\n        \n        this.qaMetrics.completeness = Math.min(100, (transcriptSegments / Math.max(1, expectedSegments)) * 100);\n        return this.qaMetrics.completeness;\n    }\n    \n    /**\n     * End QA session and generate report\n     */\n    endQASession() {\n        if (!this.currentSession) {\n            console.warn('\u26a0\ufe0f No active QA session to end');\n            return null;\n        }\n        \n        // Stop audio recording\n        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {\n            this.mediaRecorder.stop();\n        }\n        \n        // Calculate final metrics\n        this.calculateWER();\n        this.calculateAccuracy();\n        this.calculateLatency();\n        this.calculateCompleteness();\n        \n        const report = this.generateQAReport();\n        \n        console.log('\ud83d\udcca QA Session completed:', report);\n        \n        // Clean up\n        this.currentSession = null;\n        \n        return report;\n    }\n    \n    /**\n     * Generate comprehensive QA report\n     */\n    generateQAReport() {\n        const session = this.currentSession;\n        const sessionDuration = Date.now() - session.startTime;\n        \n        const report = {\n            session: {\n                id: session.id,\n                duration_ms: sessionDuration,\n                start_time: new Date(session.startTime).toISOString(),\n                end_time: new Date().toISOString()\n            },\n            \n            metrics: {\n                wer: parseFloat(this.qaMetrics.wer.toFixed(1)),\n                accuracy: parseFloat(this.qaMetrics.accuracy.toFixed(1)),\n                latency: parseFloat(this.qaMetrics.latency.toFixed(0)),\n                completeness: parseFloat(this.qaMetrics.completeness.toFixed(1))\n            },\n            \n            audio_analysis: {\n                total_chunks: session.audioChunks.length,\n                total_size_bytes: session.audioChunks.reduce((sum, chunk) => sum + chunk.size, 0),\n                avg_chunk_size: session.audioChunks.length > 0 ? \n                    session.audioChunks.reduce((sum, chunk) => sum + chunk.size, 0) / session.audioChunks.length : 0\n            },\n            \n            transcript_analysis: {\n                total_segments: session.transcriptSegments.length,\n                total_words: session.metrics.totalWords,\n                avg_confidence: parseFloat((session.metrics.avgConfidence * 100).toFixed(1)),\n                interim_segments: session.transcriptSegments.filter(s => s.isInterim).length,\n                final_segments: session.transcriptSegments.filter(s => !s.isInterim).length\n            },\n            \n            quality_issues: {\n                total_errors: session.metrics.errors.length,\n                duplicates: this.qaMetrics.duplicates,\n                low_confidence_segments: session.transcriptSegments.filter(s => s.confidence < 0.7).length,\n                high_latency_segments: session.transcriptSegments.filter(s => s.latency > 2000).length\n            },\n            \n            performance_assessment: this.assessQAPerformance(),\n            \n            passed: {\n                wer_target: this.qaMetrics.wer <= 10,\n                accuracy_target: this.qaMetrics.accuracy >= 95,\n                latency_target: this.qaMetrics.latency < 500,\n                completeness_target: this.qaMetrics.completeness >= 90,\n                overall: false\n            }\n        };\n        \n        // Overall pass/fail\n        report.passed.overall = \n            report.passed.wer_target && \n            report.passed.accuracy_target && \n            report.passed.latency_target && \n            report.passed.completeness_target;\n        \n        return report;\n    }\n    \n    /**\n     * Assess QA performance against targets\n     */\n    assessQAPerformance() {\n        const assessments = [];\n        \n        // WER Assessment\n        if (this.qaMetrics.wer <= 5) {\n            assessments.push('Excellent transcription accuracy');\n        } else if (this.qaMetrics.wer <= 10) {\n            assessments.push('Good transcription accuracy');\n        } else {\n            assessments.push('Transcription accuracy needs improvement');\n        }\n        \n        // Latency Assessment\n        if (this.qaMetrics.latency < 300) {\n            assessments.push('Excellent response time');\n        } else if (this.qaMetrics.latency < 500) {\n            assessments.push('Good response time');\n        } else {\n            assessments.push('Response time exceeds target');\n        }\n        \n        // Completeness Assessment\n        if (this.qaMetrics.completeness >= 95) {\n            assessments.push('Complete audio coverage');\n        } else if (this.qaMetrics.completeness >= 85) {\n            assessments.push('Good audio coverage');\n        } else {\n            assessments.push('Missing audio segments detected');\n        }\n        \n        return assessments;\n    }\n    \n    /**\n     * Get current QA statistics\n     */\n    getStatistics() {\n        if (!this.currentSession) {\n            return { active: false };\n        }\n        \n        return {\n            active: true,\n            sessionId: this.currentSession.id,\n            duration: Date.now() - this.currentSession.startTime,\n            segments: this.currentSession.transcriptSegments.length,\n            audioChunks: this.currentSession.audioChunks.length,\n            currentMetrics: {\n                wer: this.qaMetrics.wer,\n                accuracy: this.qaMetrics.accuracy,\n                latency: this.qaMetrics.latency,\n                completeness: this.qaMetrics.completeness\n            }\n        };\n    }\n    \n    /**\n     * Export QA data for analysis\n     */\n    exportQAData() {\n        if (!this.currentSession) return null;\n        \n        return {\n            session: this.currentSession,\n            metrics: this.qaMetrics,\n            timestamp: new Date().toISOString()\n        };\n    }\n}\n\n// Initialize comprehensive QA pipeline\nwindow.comprehensiveQA = new ComprehensiveQAPipeline();\n\nconsole.log('\u2705 Comprehensive QA Pipeline loaded');"